ML Engineer



Feature Computation and Storage Platform



빅데이터 / 데이터의 경계가 모호하긴 함

=> 분산 처리 기술을 사용하는 이유

* 여러개의 PC에서 데이터 처리해서 산출
* 하나의 PC에서 처리해서 가져올 수 있으면 빅데이터라고 보긴 어려울 것
* computer memory 대충 16GB인데
* 이때 처리할 수 있는 데이터 기껏해야 4기가임
* 따라서 생각보다 빅데이터가 엄청 크진 않음



> 현업
>
> 초당 50만개 데이터가 들어옴
>
> 하루치 데이터 학습 모아서 
>
> 거의 300GB 넘어감
>
> 크롤링된 데이터가 하루 이틀 서비스 하는 것이 아니기 때문에
>
> single pc로 처리할 수 없는 양이 모일 것임
>
> => 빅데이터로 중요한 건 log 수집 임
>
> 계속 수집할 수 있는지
>
> 한달 동안 얼마나 모일 수 있는지
>
> 그러면 빅데이터로서 의미 있음



### Hadoop, Spark를 사용한 프로젝트의 빅데이터 양이 적을 때 어떤 측면을 어필?

데이터 양이 적다 => 앞으로 데이터 양이 많아질 것 같다.

빅데이터 : 서비스의 영속성을 위해



쿠팡

하루 300만건식 들어오니깐 mySQL로 처리할 수 없었음

빅데이터로 옮겨가서 영속성 있게 서비스 할 수 있도록

중요한건 확장성!



네이버 뉴스 데이터가 너무 적으면

뉴스 뿐만 아니라 블로그 혹은 SNS데이터를 가져와서 활용하고 하면 데이터 양은 무궁무진하게 커질 수 있음



파이프라인 구축해 놓고 확장할 수 있는 가능성을 열어 놓으면 충분히 어필됨



### 네이버 뉴스  크롤링 시 10분 이상 소요되는데, 어느 시점에서 크롤링을 동작하면 좋을지?

현재 1시간 => 10분이상 소요

전혀 문제될 것이 없음

=> schedule interval이 한시간이면 한시간 동안 모든 데이터를 처리하고 다음 스케줄을 실행할 수 있음

그럼 30분 마다? 돌릴 수 도 있겠네

처리하는게 한시간치가 10분정도 걸리는데

30분마다 처리하면 6분만에 될 수 도 있겠네?

interval 안에만 해결하면 되는 일임



traffic이 너무 많으면 구분을 지어서

첫 째 뉴스 url만 크롤링하는거 queue에 실시간으로 링크 넣어 줌

뒷 프로세스는 url 읽어서 파일 처리 => 여러개를 붙일 수 있음



병렬 처리

replica

지금은 10분밖에 소요가 안되기 때문에 이걸 걱정할 일은 아님



### 원본 데이터 경제 기사 가져오는데, 우리가 활용할 수 있는 법이 있을까?

바로 앞 팀에서는 주식 관련 경제 읽어와서 키워드 만들어서 키워드가 현재 얼마나 많이 검색이 되고 있는지

관련 있는 것 까지 제공

크롤링 해서 워드 클라우드 만들어서 트렌드 시각화 까지 하는 것에 일단 집중하고

월별 트렌드 혹은 올해의 뉴스 등의 데이터 뽑아보기

경제 기사랑 코스피 지수 연결 짓는 것이 가장 무난



일자별 주식이 폭락했는지 폭등했는지

연준 발표, 나스닥 지수 비교



### 경제 기사에 있는 경제 단어의 뜻을 보여주는 기능

사용자가 기사를 읽으면 경제 단어가 매칭이 될 때 하이라이트 되고

단어에 대한 설명이 보임



뉴스 기사에서 나타나는 경제 용여 단어 테이블

경제 기사를 전부 가지고 있는 경제 단어 테이블



해당 단어가 경제 용어 단어에 일치하는지

모든 테이블에 대해 검사해야되는데 시간이 오래 걸릴 것으로 예상이 됨



단어 매칭하는데 적합한 라이브러리

find만 써도 충분히 구현 됨 => 최적화 되어서 나옴



professional하게 해보고 싶으면 특정 용어를 찾는 정규 표현식 만들어서



비트코인 전체를 링크를 걸어서 보여줄 것인데

어떻게 하이퍼링크 잘 전환 해줄지



단어 찾는건 그냥 금방 됨



client 사이드에서 하이퍼 링크를 만들 것인지

server 사이드에서 하이퍼 링크를 만들 것인지(미리 만들어 놓고 client에는 제공만)



### pyspark와 hadoop 동시에 사용하고 싶은데 뉴스 데이터 크롤링 하고 hdfs에 저장하고 정제된 데이터는 db에 저장 할 필요 있음 처리할 때 dhfs에서 불러와서 db로 넘기는 과정이 맞는건가?



db를 2개를 운영하는 것에 대한 고민

실제 현업에서도 아카이빙을 계속 함



어떤 개념?

백에서 빠르게 제공해야되는데 갠며이면 db에서 데이터를 관리하는 것 도 맞고

장기적인 데이터를 기반으로 insight를 뽑아낼 거면 hdfs

=> 서비스 layer, data warehouse archieving을 일반적으로 두개 다 함



중복된 데이터가 여기저기 산개되는게 현업에서도 하고 있는 것임

hadoop archeiving

elastic search

redis

다 저장함

사용하는 케이스에 따라서 유도리 있게 복사 저장



지금 유저 케이스에서는 MongoDB 괜찮을 듯?

word cloud 만들거니깐 hdfs에도 저장하고



### 현재 보고 있는 기사와 관련된 기사 추천 기능

### 기사마다 태그를 달아서 태그에 보내서 추천, 많이 등장하는 단어에 대해 추천 현업에서는 어떤식으로 추천하는지?

추천 알고리즘 자체는 상황에 따라 다름

ex 광고 쪽에서는 노출된 광고를 클릭하는지 안하는지

여러가지 주제에 대해 history 모아서 진행

structued data set을 사용하기 때문에 일반적인 머신러닝에 넣을 수 있음



nlt? 는 대표적으로 wordcloud기반으로 많이 하긴함

가장 핵심 기술이긴 함



여러 document들이 있을 때 document와 document의 유사성

코사인 유사도

키워드가 중요한지 중요하지 않은지 고민



모든 뉴스에 삼성전자가 다 들어가 있는데 그중에서 어떤 단어가 중요한지 알아야함

삼성전자라는 단어가 들어갔음이 중요한거지 뉴스의 핵심이 되지는 않음

이런걸 분류할 때 쓰는게 tf/rdf

트위터에서 제공하는 모델도 있음



### 기사 카테고리 정해져 있는데 사용자 서비스 중에서 읽은 기사에대한 카테고리별로 그래프 그려줌

모든 기록을 저장함

db에 리스트로 저장됨

쿠키, 해당 사용자가 방문한 기록 => 

rdb에 latest link

저장 시점은? request들어오면 그냥 바로 저장함

케바케임

